# Домашнее задание №4 

## Что нужно сделать

Необходимо реализовать пайплайн обработки свечей, аналогичный тому, что был в дз3, при этом добавив сюда логику генерации 
и получения данных о ценах и свечах через kafka producer и consumer.

То есть вам нужно реализовать такой же пайплайн, только в качестве транспорта данных между различными стадиями, вы будете
использовать kafka.

## Что конкретно нужно сделать

1. Запустить команду 
    ```shell
    docker-compose up -d
    ```
    или запустить контейнеры через IDE, перейдя в файл [docker-compose.yml](docker-compose.yml) 
2. После запуска контейнеров c kafka, необходимо перейти в kafka-ui по адресу https://localhost:8090 и создать там 
топик (или топики в зависимости от реализации) для обработки цен и свечей.
3. После того как окружение готово, можно перейти к написанию producer и consumer
   1. **Consumer**
      1. В папке [cmd/consumer](./cmd/consumer) необходимо реализовать логику старта приложения consumer, которое будет 
      подключаться к брокерам kafka и создавать consumer group клиента, который будет считывать сообщения из kafka.
      2. Для работы с kafka в go используется распространенная библиотека [sarama](https://github.com/IBM/sarama).
      Пример того, как создавать consumer group можно посмотреть в папке [examples](https://github.com/IBM/sarama/tree/main/examples/consumergroup)
      3. В sarama есть интерфейс [ConsumerGroupHandler](https://github.com/IBM/sarama/blob/main/consumer_group.go#L1072). 
      Данный интерфейс реализован в файле [internal/infrastructure/consumer/prices.go](./internal/infrastructure/consumer/prices.go).
      Вам необходимо разобраться, какая бизнес логика должна зашиваться в каждый из методов и реализовать ее так, чтобы consumer работал корректно.
      4. После того, как все реализовано, необходимо убедиться в том, что приложение consumer умеет корректно завершаться.
      Подробнее о том, что такое gracefully shutdown можно почитать [тут](https://habr.com/ru/articles/771626/)
   2. **Producer**
      1. В папке [cmd/producer](./cmd/producer) необходимо реализовать логику старта приложения producer, которые будет
      подключаться к брокерам kafka и создавать producer клиента, который будет генерировать сообщения о ценах и свечах 
      (все зависит от того, как вы захотите это реализовать) и отправлять их в топики kafka.
      2. Для работы с kafka в go используется распространенная библиотека [sarama](https://github.com/IBM/sarama).
      Пример того, как создавать producer можно посмотреть [тут](https://gist.github.com/RonnanSouza/a62e2fff0acd6e5d1271d0da0ef1e9b3)
      3. Внутри папки [internal/infrastructure/producer](./internal/infrastructure/producer) будут находиться продюсеры. 
      Часть логики для отправки сообщений с ценами я уже реализовал, вам необходимо добавить логику создания сообщения с ценой и его отправкой
      4. Также в рамках логики отправки сообщения нужно сделать custom partitioner, подробнее о том, зачем это нужно, будет написано ниже.
      О том, что такое кастомный partitioner можно почитать [тут](https://pkg.go.dev/github.com/Shopify/sarama#PartitionerConstructor)
      5. После того, как все реализовано, необходимо убедиться в том, что приложение producer умеет корректно завершаться.
      Подробнее о том, что такое gracefully shutdown можно почитать [тут](https://habr.com/ru/articles/771626/)
4. После того, как все реализовано, необходимо запустить producer и 2 consumer, образовав consumer group 
   1. Отправляя сообщения от producer, они должны считываться на стороне consumer и записывать в файлы свечи **батчами по 10 свечей в каждом батче**. 
   Что такое батчи можно почитать [тут](https://uchet-jkh.ru/i/cto-takoe-batcing/). 
5. При остановке consumer, все данные, которые находятся в обработке на стороне consumer, должны закончить обрабатываться и записаться в файл.
Producer при этом может продолжать работать. 
6. При остановке producer, все данные, которые находятся в обработке на стороне producer, должны закончить обрабатываться и отправиться в kafka.
Consumer при этом может продолжать работать.

## Как создать топики

После запуска docker-compose перейти в kafka-ui и создать 2 топика, в каждом топике 3 партиции. 

* Топик для отправки цен 
* Топик для отправки свечей

Подробнее про то, как это сделать можно почитать в конце статьи [тут](https://habr.com/ru/articles/738874/)

## Бизнес логика custom partitioner

* Перед отправкой сообщения, нужно определить, в какую партицию его положить. Логика такая
  * Для отправки цен партицию

## Критерии приемки

* Реализован consumer и вся его бизнес логика

